# 카프카 개요와 특성

---

## 왜 빠른가?

### 1. 디스크 기반 순차 쓰기 (Sequential Disk I/O)

메모리가 아니라 디스크에 append-only 로그로 저장하지만 순차 I/O 덕분에 캐시 친화적이며, 페이지 캐시 활용으로 실질적으로 메모리 쓰기와 유사한 속도를 보인다.

#### 상세 설명

일반적으로 디스크는 느리다고 생각하지만, **순차 쓰기(Sequential Write)**는 랜덤 쓰기보다 100배 이상 빠르다. 카프카는 모든 메시지를 로그 파일 끝에 순서대로 추가(append)하기 때문에 HDD에서도 높은 throughput을 달성한다.

```
┌─────────────────────────────────────────────────────────────────┐
│                    디스크 I/O 성능 비교                           │
├─────────────────────────────────────────────────────────────────┤
│                                                                  │
│   랜덤 I/O (Random)         순차 I/O (Sequential)                │
│   ┌───┐ ┌───┐ ┌───┐         ┌───┬───┬───┬───┬───┬───┐           │
│   │ 3 │ │ 7 │ │ 1 │         │ 1 │ 2 │ 3 │ 4 │ 5 │ 6 │           │
│   └─┬─┘ └─┬─┘ └─┬─┘         └───┴───┴───┴───┴───┴───┘           │
│     │     │     │             ────────────────────►              │
│     ▼     ▼     ▼             연속된 위치에 순서대로 쓰기           │
│   헤드가 여러 위치 이동                                           │
│   (Seek Time 발생)            Seek 없이 연속 쓰기                 │
│                                                                  │
│   ~100 IOPS                   ~100,000+ IOPS                     │
│   (~10ms/operation)           (~0.01ms/operation)                │
├─────────────────────────────────────────────────────────────────┤
│   💡 순차 쓰기는 랜덤 쓰기보다 약 100~1000배 빠름                   │
└─────────────────────────────────────────────────────────────────┘
```

#### OS 페이지 캐시 활용

```
┌──────────────────────────────────────────────────────────────────┐
│                     페이지 캐시 동작 원리                          │
├──────────────────────────────────────────────────────────────────┤
│                                                                   │
│  [Producer]                                                       │
│      │                                                            │
│      ▼ write()                                                    │
│  ┌─────────────────────┐                                          │
│  │   User Space        │                                          │
│  │   (Kafka Broker)    │                                          │
│  └──────────┬──────────┘                                          │
│             │                                                     │
│             ▼                                                     │
│  ┌─────────────────────┐      ┌─────────────────────┐             │
│  │   Kernel Space      │      │                     │             │
│  │   ┌─────────────┐   │      │    Disk             │             │
│  │   │ Page Cache  │◄──┼──────┤    (비동기 flush)    │             │
│  │   │ (RAM)       │   │      │                     │             │
│  │   └─────────────┘   │      └─────────────────────┘             │
│  └─────────────────────┘                                          │
│                                                                   │
│  📌 쓰기: 페이지 캐시에 즉시 저장 → OS가 비동기로 디스크 flush        │
│  📌 읽기: 최근 데이터는 페이지 캐시에서 바로 반환 (디스크 접근 X)      │
└──────────────────────────────────────────────────────────────────┘
```

- 리눅스의 기본 페이지 크기는 4KB이며, HugePage를 사용하면 2MB/1GB 단위까지 확대할 수 있다. 카프카는 append-only 로그를 순차적으로 읽고 쓰므로, 한 번 로드된 페이지가 LRU에 남아 있는 동안 높은 캐시 히트율을 유지한다.
- 페이지 캐시의 `write-back` 정책 덕분에 `fsync()`를 호출하기 전까지는 커널이 배치로 디스크에 flush 하여 디스크 섹터 단위(512B~4KB) 쓰기 횟수를 줄인다.
#### 예시: 성능 수치

| 방식 | 처리량 (MB/s) | 지연시간 |
|------|-------------|---------|
| HDD 랜덤 쓰기 | ~1-2 | ~10ms |
| HDD 순차 쓰기 | ~100-200 | ~1ms 미만 |
| SSD 순차 쓰기 | ~500-2000 | ~0.1ms |
| 메모리 | ~10,000+ | ~ns |

---

### 2. 배치와 압축 (Batching & Compression)

프로듀서가 여러 메시지를 배치로 묶고 압축해 네트워크 왕복 횟수를 줄인다.

#### 상세 설명

개별 메시지를 하나씩 전송하면 네트워크 오버헤드(TCP handshake, ACK 대기)가 크다. 카프카 프로듀서는 `linger.ms`와 `batch.size` 설정으로 여러 메시지를 모아 한 번에 전송한다.

```
┌────────────────────────────────────────────────────────────────────┐
│                      배치 전송 비교                                 │
├────────────────────────────────────────────────────────────────────┤
│                                                                     │
│  [개별 전송 - 비효율적]                                              │
│                                                                     │
│  Producer          Network          Broker                         │
│     │                                   │                          │
│     │──── msg1 ────────────────────────►│  RTT 1                   │
│     │◄─── ack ──────────────────────────│                          │
│     │──── msg2 ────────────────────────►│  RTT 2                   │
│     │◄─── ack ──────────────────────────│                          │
│     │──── msg3 ────────────────────────►│  RTT 3                   │
│     │◄─── ack ──────────────────────────│                          │
│                                                                     │
│  총 시간: 3 × RTT + 3 × 처리시간                                     │
│                                                                     │
├────────────────────────────────────────────────────────────────────┤
│                                                                     │
│  [배치 전송 - 효율적]                                                │
│                                                                     │
│  Producer          Network          Broker                         │
│     │                                   │                          │
│     │─── [msg1,msg2,msg3] ─────────────►│  RTT 1                   │
│     │◄─── ack ──────────────────────────│                          │
│                                                                     │
│  총 시간: 1 × RTT + 1 × 처리시간 (🚀 3배 빠름)                       │
│                                                                     │
└────────────────────────────────────────────────────────────────────┘
```

#### 압축 효과

```
┌────────────────────────────────────────────────────────────────────┐
│                        압축 전송 흐름                               │
├────────────────────────────────────────────────────────────────────┤
│                                                                     │
│  Producer                    Broker                    Consumer    │
│  ┌─────────┐                ┌─────────┐               ┌─────────┐  │
│  │ 원본    │   압축 전송     │ 압축된   │   압축 전송    │ 원본    │  │
│  │ 1000KB  │ ──────────────► │ 300KB   │ ─────────────►│ 1000KB  │  │
│  │         │    (gzip)      │ (저장)   │   (그대로)    │ (해제)  │  │
│  └─────────┘                └─────────┘               └─────────┘  │
│                                                                     │
│  지원 압축 알고리즘:                                                 │
│  ┌────────────┬──────────┬─────────┬──────────────┐                │
│  │ 알고리즘    │ 압축률    │ CPU 사용 │ 추천 용도     │                │
│  ├────────────┼──────────┼─────────┼──────────────┤                │
│  │ none       │ 0%       │ 최소    │ 이미 압축된 데이터│              │
│  │ gzip       │ ~70%     │ 높음    │ 네트워크 비용 절감│              │
│  │ snappy     │ ~50%     │ 낮음    │ 실시간 스트리밍  │               │
│  │ lz4        │ ~55%     │ 매우낮음 │ 고성능 요구    │                │
│  │ zstd       │ ~65%     │ 중간    │ 균형 잡힌 선택  │                │
│  └────────────┴──────────┴─────────┴──────────────┘                │
└────────────────────────────────────────────────────────────────────┘
```

#### 예시: Producer 설정

```properties
# 배치 설정
batch.size=16384          # 배치 최대 크기 (16KB)
linger.ms=5               # 최대 5ms 대기 후 전송

# 압축 설정
compression.type=lz4      # lz4 압축 사용
```

---

### 3. 제로-카피 전송 (Zero-Copy Transfer)

브로커는 파일 시스템 캐시에서 소켓으로 데이터를 직접 전송(sendfile)해 CPU 오버헤드를 최소화한다.

#### 상세 설명

일반적인 데이터 전송은 커널 ↔ 유저 공간 간 복사가 여러 번 발생한다. 제로-카피는 `sendfile()` 시스템 콜을 사용해 이 복사를 없앤다.

```
┌─────────────────────────────────────────────────────────────────────┐
│                 일반 전송 vs 제로-카피 전송                          │
├─────────────────────────────────────────────────────────────────────┤
│                                                                      │
│  [일반 전송 - 4번 복사]                                               │
│                                                                      │
│    Disk ──①──► Kernel Buffer ──②──► User Buffer                    │
│                                           │                         │
│                                          ③                          │
│                                           ▼                         │
│    NIC  ◄──④── Socket Buffer ◄───────────┘                         │
│                                                                      │
│    ① read(): 디스크 → 커널 버퍼                                       │
│    ② copy:   커널 버퍼 → 유저 버퍼 (context switch)                   │
│    ③ write(): 유저 버퍼 → 소켓 버퍼 (context switch)                  │
│    ④ send:   소켓 버퍼 → NIC                                         │
│                                                                      │
│    📊 총 4번 복사 + 2번 컨텍스트 스위치                                │
│                                                                      │
├─────────────────────────────────────────────────────────────────────┤
│                                                                      │
│  [제로-카피 전송 - 0번 복사]                                          │
│                                                                      │
│    Disk ──────► Kernel Buffer (Page Cache)                          │
│                        │                                            │
│                        │ sendfile()                                 │
│                        │ (DMA 직접 전송)                              │
│                        ▼                                            │
│    NIC  ◄────────────────                                           │
│                                                                      │
│    📊 CPU 복사 없음, 1번 시스템 콜                                     │
│                                                                      │
└─────────────────────────────────────────────────────────────────────┘
```

#### 성능 비교

```
┌─────────────────────────────────────────────────┐
│              제로-카피 성능 향상                   │
├─────────────────────────────────────────────────┤
│                                                  │
│  전송 크기: 1GB 파일                              │
│                                                  │
│  일반 전송:                                       │
│  ├── CPU 사용률: 80%                             │
│  ├── 전송 시간: 10초                              │
│  └── 메모리 대역폭: 4GB (4번 복사)                 │
│                                                  │
│  제로-카피:                                       │
│  ├── CPU 사용률: 10%   (🔽 87.5% 감소)           │
│  ├── 전송 시간: 3초    (🔽 70% 감소)             │
│  └── 메모리 대역폭: 1GB (복사 없음)               │
│                                                  │
│  💡 대량 데이터 전송 시 효과가 극대화됨             │
└─────────────────────────────────────────────────┘
```

---

### 4. 수평 확장 (Horizontal Scaling)

토픽을 파티션으로 나누고 파티션을 여러 브로커에 분산함으로써 병렬 처리량을 높인다.

#### 상세 설명

카프카는 토픽을 여러 파티션으로 나누고, 각 파티션을 서로 다른 브로커에 분산 배치한다. 프로듀서와 컨슈머는 여러 파티션에 병렬로 읽고 쓸 수 있다.

```
┌──────────────────────────────────────────────────────────────────────┐
│                        파티션 분산 아키텍처                            │
├──────────────────────────────────────────────────────────────────────┤
│                                                                       │
│                          Topic: orders                                │
│                               │                                       │
│           ┌───────────────────┼───────────────────┐                   │
│           │                   │                   │                   │
│           ▼                   ▼                   ▼                   │
│     ┌──────────┐        ┌──────────┐        ┌──────────┐              │
│     │Partition │        │Partition │        │Partition │              │
│     │    0     │        │    1     │        │    2     │              │
│     └────┬─────┘        └────┬─────┘        └────┬─────┘              │
│          │                   │                   │                    │
│          ▼                   ▼                   ▼                    │
│     ┌──────────┐        ┌──────────┐        ┌──────────┐              │
│     │ Broker 1 │        │ Broker 2 │        │ Broker 3 │              │
│     │ (Leader) │        │ (Leader) │        │ (Leader) │              │
│     └──────────┘        └──────────┘        └──────────┘              │
│          │                   │                   │                    │
│          └───────────────────┼───────────────────┘                    │
│                              │                                        │
│                    ┌─────────┴─────────┐                              │
│                    │  Kafka Cluster    │                              │
│                    │  (3 Brokers)      │                              │
│                    └───────────────────┘                              │
│                                                                       │
│  📌 각 파티션은 독립적으로 읽기/쓰기 가능                               │
│  📌 파티션 수 = 최대 병렬 컨슈머 수                                     │
└──────────────────────────────────────────────────────────────────────┘
```

#### 병렬 처리 예시

```
┌──────────────────────────────────────────────────────────────────────┐
│                     병렬 처리량 확장                                   │
├──────────────────────────────────────────────────────────────────────┤
│                                                                       │
│  [단일 파티션]                     [6개 파티션]                        │
│                                                                       │
│  Producer ──► P0 ──► Consumer     Producer ──┬► P0 ──► Consumer 1    │
│                                              ├► P1 ──► Consumer 2    │
│  처리량: 10,000 msg/s                        ├► P2 ──► Consumer 3    │
│                                              ├► P3 ──► Consumer 4    │
│                                              ├► P4 ──► Consumer 5    │
│                                              └► P5 ──► Consumer 6    │
│                                                                       │
│                                    처리량: 60,000 msg/s (🚀 6배)      │
│                                                                       │
├──────────────────────────────────────────────────────────────────────┤
│                                                                       │
│  확장 공식:                                                            │
│  ┌────────────────────────────────────────────────────────────┐       │
│  │  총 처리량 = 파티션 수 × 단일 파티션 처리량                    │       │
│  │                                                            │       │
│  │  예) 파티션 12개 × 10,000 msg/s = 120,000 msg/s            │       │
│  └────────────────────────────────────────────────────────────┘       │
│                                                                       │
└──────────────────────────────────────────────────────────────────────┘
```

---

## 특징

### 1. 분산 로그 저장소 (Distributed Log)

이벤트 스트림 데이터를 길게 보존하며, 여러 컨슈머 그룹이 독립적으로 읽는다.

```
┌──────────────────────────────────────────────────────────────────────┐
│                      분산 로그 구조                                   │
├──────────────────────────────────────────────────────────────────────┤
│                                                                       │
│  Partition 0 (Append-Only Log)                                       │
│  ┌────┬────┬────┬────┬────┬────┬────┬────┬────┬────┐                 │
│  │ 0  │ 1  │ 2  │ 3  │ 4  │ 5  │ 6  │ 7  │ 8  │ 9  │ ◄── 새 메시지    │
│  └────┴────┴────┴────┴────┴────┴────┴────┴────┴────┘                 │
│    ▲                   ▲                        ▲                    │
│    │                   │                        │                    │
│  Consumer A          Consumer B              Consumer C              │
│  (offset: 0)        (offset: 3)             (offset: 8)              │
│                                                                       │
│  📌 각 컨슈머 그룹은 자신만의 오프셋을 관리                             │
│  📌 같은 데이터를 여러 컨슈머가 독립적으로 소비                          │
└──────────────────────────────────────────────────────────────────────┘
```

### 2. 백프레셔 내성 (Backpressure Resistance)

컨슈머가 느려도 브로커에 데이터가 남아 있어 재처리와 리플레이가 가능하다.

```
┌──────────────────────────────────────────────────────────────────────┐
│                   기존 메시지 큐 vs 카프카                             │
├──────────────────────────────────────────────────────────────────────┤
│                                                                       │
│  [기존 메시지 큐 - Push 모델]                                          │
│                                                                       │
│  Producer ──► Queue ──push──► Consumer (느림)                        │
│                 │                 │                                   │
│                 │    메모리 초과!   │                                  │
│                 ▼                 ▼                                   │
│              💥 OOM           메시지 유실                              │
│                                                                       │
├──────────────────────────────────────────────────────────────────────┤
│                                                                       │
│  [카프카 - Pull 모델]                                                  │
│                                                                       │
│  Producer ──► Broker (Disk) ◄──pull── Consumer (느림)                │
│                 │                        │                           │
│                 │   디스크에 안전하게      │   자기 속도대로             │
│                 │   보존 (7일 기본)       │   가져감                   │
│                 ▼                        ▼                           │
│              ✅ 안전                    ✅ 유실 없음                    │
│                                                                       │
└──────────────────────────────────────────────────────────────────────┘
```

### 3. 강력한 복제 모델 (ISR-based Replication)

ISR 기반 복제로 브로커 장애 시 빠르게 리더를 교체하고 내구성을 제공한다.

```
┌──────────────────────────────────────────────────────────────────────┐
│                      ISR 복제 모델                                    │
├──────────────────────────────────────────────────────────────────────┤
│                                                                       │
│  Partition 0 (Replication Factor = 3)                                │
│                                                                       │
│  ┌─────────────┐    ┌─────────────┐    ┌─────────────┐               │
│  │  Broker 1   │    │  Broker 2   │    │  Broker 3   │               │
│  │  ┌───────┐  │    │  ┌───────┐  │    │  ┌───────┐  │               │
│  │  │Leader │  │───►│  │Follower│ │    │  │Follower│ │               │
│  │  │ P0    │  │    │  │  P0   │  │    │  │  P0   │  │               │
│  │  └───────┘  │    │  └───────┘  │    │  └───────┘  │               │
│  └─────────────┘    └─────────────┘    └─────────────┘               │
│        │                  ▲                  ▲                        │
│        │                  │                  │                        │
│        └──────── 복제 ────┴──────────────────┘                        │
│                                                                       │
│  ISR (In-Sync Replicas): 리더와 동기화된 복제본 집합                    │
│  ┌────────────────────────────────────────────────────────────┐      │
│  │  • min.insync.replicas=2 설정 시:                          │      │
│  │    - 최소 2개 복제본이 동기화되어야 쓰기 성공                 │      │
│  │    - 1개 브로커 장애에도 데이터 무손실 보장                   │      │
│  └────────────────────────────────────────────────────────────┘      │
│                                                                       │
│  [장애 복구 시나리오]                                                  │
│                                                                       │
│  Broker 1 장애 발생! ──► Broker 2가 새 리더로 선출 (~ms 단위)          │
│                         (ISR에 있었으므로 데이터 무손실)                │
└──────────────────────────────────────────────────────────────────────┘
```

### 4. 플랫폼 생태계

Connect, Streams, ksqlDB 등과 결합해 데이터 파이프라인을 구성할 수 있다.

```
┌──────────────────────────────────────────────────────────────────────┐
│                     카프카 생태계                                     │
├──────────────────────────────────────────────────────────────────────┤
│                                                                       │
│                        ┌─────────────┐                               │
│                        │   ksqlDB    │                               │
│                        │  (SQL 분석)  │                               │
│                        └──────┬──────┘                               │
│                               │                                      │
│  ┌─────────────┐    ┌────────┴────────┐    ┌─────────────┐          │
│  │   Kafka     │    │                 │    │   Kafka     │          │
│  │   Connect   │───►│  Kafka Broker   │◄───│   Streams   │          │
│  │  (Source)   │    │    Cluster      │    │  (실시간    │          │
│  └──────┬──────┘    └────────┬────────┘    │   처리)     │          │
│         │                    │             └─────────────┘          │
│         ▲                    ▼                                      │
│  ┌──────┴──────┐    ┌─────────────┐                                 │
│  │ 외부 시스템  │    │   Kafka     │                                 │
│  │ - MySQL     │    │   Connect   │                                 │
│  │ - MongoDB   │    │  (Sink)     │                                 │
│  │ - S3        │    └──────┬──────┘                                 │
│  └─────────────┘           │                                        │
│                            ▼                                        │
│                    ┌─────────────┐                                  │
│                    │ 외부 시스템  │                                  │
│                    │ - ES        │                                  │
│                    │ - HDFS      │                                  │
│                    │ - Redis     │                                  │
│                    └─────────────┘                                  │
└──────────────────────────────────────────────────────────────────────┘
```

---

## 장점

### 1. 고성능/저지연

대규모 데이터 처리에도 안정적인 throughput.

```
┌──────────────────────────────────────────────────────────────────────┐
│                      카프카 성능 벤치마크                              │
├──────────────────────────────────────────────────────────────────────┤
│                                                                       │
│  테스트 환경: 3 브로커, 파티션 6개, 복제 팩터 3                          │
│                                                                       │
│  ┌────────────────────────────────────────────────────────────┐      │
│  │  Producer Throughput                                       │      │
│  │  ══════════════════════════════════════════════ 800K/s    │      │
│  │                                                            │      │
│  │  Consumer Throughput                                       │      │
│  │  ════════════════════════════════════════════════ 900K/s  │      │
│  │                                                            │      │
│  │  End-to-End Latency (p99)                                  │      │
│  │  ██ 5ms                                                    │      │
│  └────────────────────────────────────────────────────────────┘      │
│                                                                       │
│  💡 LinkedIn 실제 사례: 1조+ 메시지/일, 1PB+ 데이터/일                  │
└──────────────────────────────────────────────────────────────────────┘
```

### 2. 확장 용이성

파티션/브로커를 추가해 수평 확장.

### 3. 내구성과 재처리

로그 보존과 오프셋 관리로 과거 데이터를 쉽게 재처리.

### 4. 다양한 클라이언트 지원

언어별 클라이언트, 커넥터, 스트림 처리 프레임워크.

---

## 단점/주의사항

### 1. 운영 복잡도

브로커, 주키퍼/KRaft, 모니터링, 스토리지 등 인프라 관리 부담.

```
┌──────────────────────────────────────────────────────────────────────┐
│                     운영 복잡도 요소                                   │
├──────────────────────────────────────────────────────────────────────┤
│                                                                       │
│  ┌─────────────────────────────────────────────────────────────┐     │
│  │                    카프카 클러스터                           │     │
│  │  ┌─────────┐  ┌─────────┐  ┌─────────┐                      │     │
│  │  │Broker 1 │  │Broker 2 │  │Broker 3 │                      │     │
│  │  └────┬────┘  └────┬────┘  └────┬────┘                      │     │
│  │       │            │            │                           │     │
│  │       └────────────┼────────────┘                           │     │
│  │                    │                                        │     │
│  │  ┌─────────────────┼─────────────────┐                      │     │
│  │  │        ZooKeeper/KRaft            │                      │     │
│  │  │  ┌─────┐  ┌─────┐  ┌─────┐       │                      │     │
│  │  │  │ZK 1 │  │ZK 2 │  │ZK 3 │       │                      │     │
│  │  │  └─────┘  └─────┘  └─────┘       │                      │     │
│  │  └───────────────────────────────────┘                      │     │
│  └─────────────────────────────────────────────────────────────┘     │
│                           │                                          │
│       ┌───────────────────┼───────────────────┐                      │
│       │                   │                   │                      │
│       ▼                   ▼                   ▼                      │
│  ┌─────────┐        ┌─────────┐        ┌─────────┐                  │
│  │모니터링  │        │알림 시스템│        │로그 관리 │                  │
│  │Grafana  │        │PagerDuty│        │스토리지  │                  │
│  └─────────┘        └─────────┘        └─────────┘                  │
│                                                                       │
│  관리 항목: 브로커 설정, 토픽 관리, ACL, 모니터링, 업그레이드...         │
└──────────────────────────────────────────────────────────────────────┘
```

### 2. 데이터 모델 제약

파티션 키 설계가 까다로우며, 크로스 파티션 트랜잭션이 제한적.

### 3. 지연 기준

밀리초 단위 지연은 가능하지만 하위 ms 실시간 시스템에는 부적합할 수 있다.

### 4. 데이터 삭제 지연

보존 기간이 길면 디스크 관리가 어렵고, compaction은 CPU를 사용한다.

---

## 사용 시 고려

```
┌──────────────────────────────────────────────────────────────────────┐
│                     카프카 도입 체크리스트                             │
├──────────────────────────────────────────────────────────────────────┤
│                                                                       │
│  1. 워크로드 분석                                                     │
│     □ 예상 메시지 크기: _______ bytes                                 │
│     □ 예상 처리량: _______ msg/s                                     │
│     □ 허용 지연시간: _______ ms                                       │
│                                                                       │
│  2. 클러스터 계획                                                     │
│     □ 브로커 수: (처리량 / 단일 브로커 처리량) × 복제 팩터             │
│     □ 파티션 수: max(예상 Producer 수, 예상 Consumer 수)              │
│     □ 복제 팩터: 프로덕션은 최소 3                                    │
│                                                                       │
│  3. 보존 정책                                                         │
│     □ retention.ms: _______ (기본 7일)                               │
│     □ retention.bytes: _______ (파티션당 최대 크기)                   │
│                                                                       │
│  4. 운영 체계                                                         │
│     □ Schema Registry 도입 여부                                       │
│     □ ACL 및 보안 설정                                                │
│     □ 모니터링 및 알림 구성                                           │
│     □ DR(재해복구) 계획                                               │
└──────────────────────────────────────────────────────────────────────┘
```

- 워크로드 특성(메시지 크기, 처리 지연 허용치)을 파악해 브로커 수와 파티션 수를 계획한다.
- 토픽별 SLA에 따라 보존 정책과 복제 팩터를 조정해 비용과 신뢰도 균형을 맞춘다.
- Schema Registry, ACL, 정합성 검증 프로세스를 포함한 운영 체계를 수립한다.
